{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342d457c",
   "metadata": {},
   "source": [
    "# Compliance Notebook Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e31748",
   "metadata": {},
   "source": [
    "## 1. Best Practices for Usage\n",
    "\n",
    "Here are some important best practices when using this RAG application:\n",
    "\n",
    "- Ask objective, specific questions related to compliance.\n",
    "- The app works best with indexed documents covering filings, sanctions, etc.\n",
    "- Avoid vague or extremely broad questions.\n",
    "- A sample of supported questions is provided in `suggested_questions.md`.\n",
    "\n",
    "Always verify answers that sound uncertain or ambiguous. This application does **not** infer beyond the indexed documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e365c",
   "metadata": {},
   "source": [
    "## 2. Load and Preview Raw Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30da02",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Ana/Desktop/compliance_RAG/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "RAW_PATH = \"data/raw\"\n",
    "print(\" === Raw files: ===\")\n",
    "for fname in os.listdir(RAW_PATH):\n",
    "    print(\"-\", fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426e289",
   "metadata": {},
   "source": [
    "## 3. Build FAISS Index (Optional - only if not yet created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.build_index import main as build_index\n",
    "\n",
    "build_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f9432",
   "metadata": {},
   "source": [
    "#falar o que foi feito aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c4eb7",
   "metadata": {},
   "source": [
    "## 4. Inspect FAISS Index Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.inspect_index import main as inspect_index\n",
    "\n",
    "inspect_index(\"data/index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falar como foi feito o index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883213d",
   "metadata": {},
   "source": [
    "## 5. Run a Sample QA Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.backend import ask_question\n",
    "\n",
    "sample_question = \"Has Tesla ever been listed on OFAC sanctions?\"\n",
    "answer = ask_question(sample_question)\n",
    "print(\"=== Answer: ===\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3020769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falar o que foi feito aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6667ca9",
   "metadata": {},
   "source": [
    "## 6. Next Steps and Suggested Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab5438",
   "metadata": {},
   "source": [
    "\n",
    "- tem que falar de novo que num contexto ideal e real, em que alimentam essa ferramenta, seriam exclusivo da Dow Jones e também vendidos por ela da forma que é hoje, mas que essa ferramenta é uma etapa de inteligência, então o cliente teria acesso à perguntas e respostas exclusivas que ele compraria em outros formatos, mas que nessa ferramenta dão a ele mais eficiencia na hora da tomada da decisão. \n",
    "\n",
    "- Aqui eu tive que obter documentos da internet para simular como seria, então as perguntas e respostas parecem óbvias e parece como \"é mesma coisa que um chat gpt\" mas não, o objetivo seria incluir os docuemntos exclusivos e tratados pela dow jones para que fossem respostas que seriam de alguma forma negociada e exclusiva do cliente e dow jones. \n",
    "\n",
    "- num contexto real, teria que adaptar a storage (não mais seria data/raw) mas seria algo na nuvem ou etc, \n",
    "\n",
    "- pipeline adaptada ao real contexto de nuvem????? \n",
    "\n",
    "- quais modelos se adaptariam melhor? OPENai? \n",
    "\n",
    "- A Pipeline foi construida de forma escalável em que na medida que houver necessidade de troca de modelos ou parâmetros, é facilmente modificada, \n",
    "\n",
    "- não foi realizado nenhum procedimento de validação formal. Acredito que num primeiro momento, a validação é verdadeira e útil aquela que é feita comparando os documentos indexados com o conteúdo das respostas. Isso foi feito iterativamente até que eu conseguisse encontrar parâmetros de temperatura, e prompt engineerign e outros, que me fizesse numa primeira versºao de POC achar que está consistênte. Claro que as perguntas e respostas, como disse estão limitadas a um contexto restrito por causa dos documentos que são em numero restrito. Numa próxima validação, entraria novas iterações como para melhorar limpeza dos textos, inclusão de outros tipos de documentos, por exemplo os que não tem texto pesquisavel e precisariam de OCR, teria que haver também validações por parte de business no sentido de entender se realmente está sendo útil as respostas e fazendo sentido com o contexto e necesisdade. \n",
    "\n",
    "- É muito oneroso executar localmente e alguns documentos como escaneados ou que tem imagens, estão sendo ainda excluidos. Somente foram tratados e incorporados à ferramenta aqueles que tem texto pesquisável\n",
    "\n",
    "- Tentei inserir no hugging face space para fazer uma simples apresentação do que seria um front end (interface da ferramenta) no entanto o modelo que eu usei, o Ollama não tem permissõs para execução lá, e então deixo para gerar um front end ou até mesmo uma API numa próxima versão. Agora o objetivo seria validar os critérios mais subjetivos de pergunta e resposta e as intenções da ferramenta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fc181",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
