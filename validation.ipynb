{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b739896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compliance RAG – Model Validation Notebook\n",
    "\n",
    "\"\"\"\n",
    "This notebook validates whether the AI system is correctly grounding answers in the retrieved documents.\n",
    "We simulate a few example questions and check if:\n",
    "\n",
    "1. The source documents actually contain the answer\n",
    "2. The LLM correctly cites or reflects the retrieved chunks\n",
    "3. There is no hallucination or overreach\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from src.qa import RAGPipeline  # Uses the FAISS index + LLM\n",
    "from pathlib import Path\n",
    "\n",
    "INDEX_PATH = Path(\"data/index\")\n",
    "qa_system = RAGPipeline(index_path=INDEX_PATH)\n",
    "\n",
    "# These questions are designed around public proxies for Dow Jones datasets\n",
    "# In production, these would reflect the client's licensed internal data\n",
    "example_questions = [\n",
    "    \"Was Tesla mentioned in any OFAC sanctions?\",\n",
    "    \"What are the latest FinCEN advisories?\",\n",
    "    \"Is there any SEC filing involving Alphabet Inc. this year?\",\n",
    "    \"List entities in the most recent FATF blacklist.\",\n",
    "    \"What is the tone of the regulatory update from the EU?\"\n",
    "]\n",
    "\n",
    "for q in example_questions:\n",
    "    print(f\"\\n\\033[1mQuestion:\\033[0m {q}\")\n",
    "    response = qa_system.ask(q)\n",
    "    print(f\"\\n\\033[1mAnswer:\\033[0m {response['answer']}\")\n",
    "    print(\"\\n\\033[1mSources:\\033[0m\")\n",
    "    for doc in response[\"sources\"]:\n",
    "        print(f\"- {doc.metadata.get('source', 'unknown')}\\n  → {doc.page_content[:300]}...\")\n",
    "\n",
    "\"\"\"\n",
    "Validation Notes:\n",
    "- For each answer, verify that the content appears in the cited source\n",
    "- If not, check whether the source passage is at least related or thematically adjacent\n",
    "- If answer seems fabricated or unsupported, mark it as hallucinated\n",
    "\n",
    "Production datasets would yield better grounding due to curated structure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c1f9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Ana/Desktop/compliance_RAG/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = Path(\"data/raw\")\n",
    "print(docs_path.exists())\n",
    "print(list(docs_path.glob(\"*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641162da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inspect_index import inspect_index\n",
    "\n",
    "indexed_docs = inspect_index(\"data/index\")\n",
    "\n",
    "for doc in indexed_docs:\n",
    "    print(f\"\\nDocument {doc['doc_id']}\")\n",
    "    print(f\"Source: {doc['source']}\")\n",
    "    print(f\"Preview: {doc['preview']}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
